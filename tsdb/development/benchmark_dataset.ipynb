{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e5ee030e-c506-488d-82ff-047937cafbce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Benchmark table schema\n",
    "\n",
    "model_name: STRING \n",
    "\n",
    "overall_metrics: STRUCT<\"micro_averaged\": STRUCT<\"f1\": float, \"recall\": float, \"precision\": float>, \"macro_averaged\": STRUCT<\"f1\": float, \"recall\": float, \"precision\": float>>\n",
    "\n",
    "per_class_metrics: STRUCT<\"ct\": STRUCT<\"f1\": float, \"recall\": float, \"precision\": float>>\n",
    "\n",
    "iou_threshold: float \n",
    "\n",
    "confidence_threshold: float\n",
    "\n",
    "# ASSUMPTIONS\n",
    "Only models from the new Ultralytics lib will be benchmarked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ed6b2d2f-318a-4a53-8af1-8f10abd339e1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "\n",
    "import mlflow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import PIL\n",
    "from torch import no_grad, Tensor, cuda, sigmoid, device, tensor\n",
    "import torch\n",
    "import pyspark.sql.types as T\n",
    "import pyspark.sql.functions as F\n",
    "from ultralytics.utils import ASSETS\n",
    "from ultralytics.utils.metrics import ConfusionMatrix\n",
    "from ultralytics.models.yolo.detect import DetectionPredictor\n",
    "\n",
    "from tsdb.ml.utils import get_model_tags, cut_square_detection, UCModelName\n",
    "# from tsdb.preprocessing.images import open_image_binary\n",
    "# from tsdb.ml.infer import load_model, make_confusion_matrix_udf\n",
    "from tsdb.ml.drift import get_struct_counts\n",
    "\n",
    "\n",
    "\n",
    "mlflow.set_registry_uri(\"databricks-uc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3a276ac7-d59a-4eff-981f-ff09d7e047d3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# torch_device = torch.device(\"cuda\") if cuda.is_available() else torch.device(\"cpu\")\n",
    "# uc_model_name = UCModelName(\"edav_dev_csels\", \"towerscout\", \"yolov10_models\")\n",
    "# uc_alias = \"medium\"\n",
    "\n",
    "# model = mlflow.pytorch.load_model(\n",
    "#         model_uri=f\"models:/{str(uc_model_name)}@{uc_alias}\",\n",
    "#         map_location=torch_device\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8543e940-819a-4d6b-96a8-a0ea0eb17db2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# print(model.names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "c3df1411-087a-4e37-9813-721d69dc846c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# df = spark.read.format(\"delta\").table(\"edav_dev_csels.towerscout.benchmark_scored\").selectExpr(\"*\", \"results.bboxes as bboxes\").limit(50)\n",
    "\n",
    "# df = df.selectExpr(\n",
    "#     '*',\n",
    "#     \"transform(bboxes, x -> x.class) AS class\",\n",
    "#     \"flatten(transform(bboxes, x -> array(x.x1, x.y1, x.x2, x.y2))) AS bboxes\",\n",
    "# )\n",
    "\n",
    "# display(df)\n",
    "\n",
    "# test_img_path = df.first()['path'].split(\":\")[1]\n",
    "# raw_bbox = df.first()['results']['bboxes']\n",
    "# gt_bboxes = []\n",
    "# gt_classes = []\n",
    "# for bbox in raw_bbox:\n",
    "#     gt_bboxes.append([bbox['x1'], bbox['y1'], bbox['x2'], bbox['y2']])\n",
    "#     gt_classes.append(bbox['class'])\n",
    "\n",
    "# gt_bboxes = np.array(gt_bboxes)\n",
    "# gt_classes = np.array(gt_classes)\n",
    "# print(test_img_path)\n",
    "# print(raw_bbox)\n",
    "# print(gt_bboxes)\n",
    "# print(gt_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "c0f8bf97-58ca-4cb5-952f-bc83bf84798d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# torch_device = device(\"cuda\") if cuda.is_available() else device(\"cpu\")\n",
    "\n",
    "# yolo_model_name = \"edav_dev_csels.towerscout.yolov10_models\"\n",
    "# yolo_alias = \"medium\"\n",
    "\n",
    "# yolo_detector = mlflow.pytorch.load_model(\n",
    "#         model_uri=f\"models:/{yolo_model_name}@{yolo_alias}\",\n",
    "#         map_location=torch_device\n",
    "#     )\n",
    "\n",
    "# yolo_detector.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "4790d401-ce33-4f15-a688-408363794692",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# yolo_detector = load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "de7b8eb1-0d22-415f-9146-4b9baceb1205",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# conf = 0.2\n",
    "# iou_thres = 0.2\n",
    "# confusion_matrix = ConfusionMatrix(nc=1, conf=conf, iou_thres=iou_thres)\n",
    "\n",
    "# test_img = PIL.Image.open(test_img_path)\n",
    "# yolo_output = yolo_detector(test_img) #.xyxyn\n",
    "\n",
    "# boxes = yolo_output[0].boxes.xyxyn\n",
    "# labels = yolo_output[0].boxes.cls\n",
    "# confs = yolo_output[0].boxes.conf\n",
    "\n",
    "\n",
    "# print(boxes)\n",
    "# print(labels)\n",
    "# print(confs)\n",
    "# result = torch.cat((boxes, confs.reshape(-1, 1), labels.reshape(-1, 1)), dim=1)\n",
    "# print(result)\n",
    "\n",
    "# print(f\"Original CM:\\n{confusion_matrix.matrix}\\n\")\n",
    "\n",
    "# for detections in yolo_output:\n",
    "#     boxes = detections.boxes.xyxyn\n",
    "#     labels = detections.boxes.cls\n",
    "#     confs = detections.boxes.conf\n",
    "#     #detection = detection.boxes.xyxy #detection.to(\"cpu\")\n",
    "#     result = torch.cat((boxes, confs.reshape(-1, 1), labels.reshape(-1, 1)), dim=1).to(\"cpu\")\n",
    "#     confusion_matrix.process_batch(detections=result, gt_bboxes=tensor(gt_bboxes), gt_cls=tensor(gt_classes))\n",
    "#     #print(detection)\n",
    "\n",
    "\n",
    "# print(f\"New CM:\\n{confusion_matrix.matrix}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "31bd4901-2cfe-4c50-8905-4ec0edd825ef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def open_image_binary(image_binary: bytes) -> tuple[Image, dict]:  # pragma: no cover\n",
    "    \"\"\"\n",
    "    A function that takes an image binary and returns a PIL image \n",
    "    and a dictionary of EXIF metadata.\n",
    "    NOTE: Unit testing forgon as ByteIO and Image.open are\n",
    "    tested already \n",
    "    \n",
    "    Args: \n",
    "        image_binary: The image binary.\n",
    "        \n",
    "    Returns:\n",
    "        A PIL image and a dictionary of EXIF metadata.\n",
    "    \"\"\"\n",
    "    image_binary = BytesIO(image_binary)\n",
    "\n",
    "    # Try to read the image and if we fail, we have to default to\n",
    "    # to the null image case\n",
    "    try:\n",
    "        image = PIL.Image.open(image_binary)\n",
    "        exif = image._getexif()\n",
    "    except FileNotFoundError:\n",
    "        image = None\n",
    "        exif = None\n",
    "    except UnicodeDecodeError:\n",
    "        image = None\n",
    "        exif = None\n",
    "\n",
    "    return image, exif\n",
    "\n",
    "def load_model(uc_model_name: UCModelName, uc_alias: str) -> DetectionPredictor:\n",
    "    \"\"\"\n",
    "    Loads a model from the UC model registry and creates a DetectionPredictor\n",
    "    object using it.\n",
    "\n",
    "    Args:\n",
    "        uc_model_name: The name of the YOLO model in UC.\n",
    "        uc_alias: The alias for the YOLO model in UC.\n",
    "    \n",
    "    Returns:\n",
    "        A DetectionPredictor class that returns parsed outputs from the loaded model.\n",
    "    \"\"\"\n",
    "\n",
    "    # set unity catalog as registry to get models from\n",
    "    mlflow.set_registry_uri(\"databricks-uc\")\n",
    "    torch_device = torch.device(\"cuda\") if cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "    yolo_model = mlflow.pytorch.load_model(\n",
    "        model_uri=f\"models:/{str(uc_model_name)}@{uc_alias}\",\n",
    "        map_location=torch_device\n",
    "    )\n",
    "    \n",
    "    predictor_args = yolo_model.args\n",
    "    predictor_args.source = ASSETS\n",
    "    predictor_args.verbose = False\n",
    "    predictor_args.show = False\n",
    "    predictor_args.save = False\n",
    "    predictor_args.save_txt = False\n",
    "\n",
    "    yolo_model_wrapper = DetectionPredictor(overrides=predictor_args)\n",
    "\n",
    "    yolo_model_wrapper.setup_model(yolo_model)\n",
    "\n",
    "    return yolo_model_wrapper\n",
    "\n",
    "\n",
    "def make_confusion_matrix_udf(uc_model_name: UCModelName, uc_alias: str, conf: float=0.5, iou_thres: float=0.5) -> callable:\n",
    "    \"\"\"\n",
    "    Returns a UDF that performs inference on a batch of labeled images and then computes the confusion matrix\n",
    "    for each row. \n",
    "    \n",
    "    Args: \n",
    "        uc_model_name: A UCModelName object that contains the name of the model in UC.\n",
    "        uc_alias: The alias for the YOLO model in UC.\n",
    "        conf: The confidence threshold. Ranges between [0,1] \n",
    "            Predicted bounding boxes with a confidence \n",
    "            below this threshold will not be considered. \n",
    "        iou_thres: The IoU threshold. Ranges between [0,1]\n",
    "            This is used to determine if a bounding box is macthed to \n",
    "            a ground truth bounding box. If a predicted bounding box is \n",
    "            matched to a ground truth bounding box, the IoU between the \n",
    "            two bounding boxes must be greater than this threshold.\n",
    "    \"\"\"\n",
    "\n",
    "    @F.pandas_udf(returnType=\"array<array<integer>>\")\n",
    "    @no_grad()\n",
    "    def confusion_matrix_udf(batch_image_bins: pd.Series, batch_bboxes: pd.Series, batch_classes: pd.Series) -> pd.Series:\n",
    "        \"\"\"\n",
    "        A UDF that performs inference on a batch of images and then computes the confusion matrix\n",
    "        for each image using the predicted boudning boxes from the model and ground truth \n",
    "        bounding boxes and labels from batch_bboxes and batch_classes.\n",
    "\n",
    "        Args:\n",
    "            batch_image_bins: A partition of image binaries\n",
    "            batch_bboxes: A partition of ground truth bounding boxes. Each element in the batch is \n",
    "                            assumed to be a 1D list of shape (num_bboxes*4,) where the first 4 \n",
    "                            elements are the coordiantes of the list are (x1,y1,x2,y2) of the \n",
    "                            first boudnding box, the next 4 are the coordinates of the 2nd bounding\n",
    "                            box and so on. We reshape this into the proper shape (num_bboxes, 4) \n",
    "                            later in the function.\n",
    "            batch_classes: A partition of ground truth labels for the bounding boxes. Each \n",
    "                            element in the batch is assumed to be a 1D list of shape (num_bboxes,). \n",
    "                            The first element is the class label of the first bounding box, the second \n",
    "                            element is the class label of the 2nd bounding box, and so on.\n",
    "\n",
    "        Returns:\n",
    "            Confusion matrices for each image in the partition.\n",
    "        \"\"\"\n",
    "\n",
    "        # load model within UDF to avoid serialization issues \n",
    "        yolo_detector = load_model(uc_model_name, uc_alias)\n",
    "        \n",
    "        num_classes = len(yolo_detector.model.names)\n",
    "        outputs = []\n",
    "\n",
    "        for image_binary, bboxes, classes in zip(batch_image_bins, batch_bboxes, batch_classes):\n",
    "            confusion_matrix = ConfusionMatrix(nc=num_classes, conf=conf, iou_thres=iou_thres)\n",
    "\n",
    "            image, _ = open_image_binary(image_binary)\n",
    "            \n",
    "            if image is None:\n",
    "                continue\n",
    "            \n",
    "            # we reshape the flattenned bounding box list to have \n",
    "            # the correct (non-flattened) shape (num_boxes, 4)\n",
    "            true_bboxes = np.array(bboxes).reshape(-1, 4)\n",
    "            true_classes = np.array(classes)\n",
    "\n",
    "            yolo_output = yolo_detector(image, stream=False)\n",
    "            \n",
    "            boxes = yolo_output[0].boxes.xyxyn  # get *normalized* bboxes coordinates as tensor of shape (num_boxes, 4)\n",
    "            labels = yolo_output[0].boxes.cls  # get class labels as tensor of shape (num_boxes, 1)\n",
    "            confs = yolo_output[0].boxes.conf  # get confidence scores as tensor of shape (num_boxes, 1)\n",
    "\n",
    "            # concatenate the tensors into a single tensor with columns [x1,y1,x2,y2,conf,label]\n",
    "            # as that is the format expected by Ultralytics' ConfusionMatrix.process_batch() function\n",
    "            result = torch.cat((boxes, confs.reshape(-1, 1), labels.reshape(-1, 1)), dim=1).to(\"cpu\")\n",
    "\n",
    "            confusion_matrix.process_batch(detections=result, gt_bboxes=tensor(true_bboxes), gt_cls=tensor(true_classes))\n",
    "\n",
    "            outputs.append(confusion_matrix.matrix)\n",
    "\n",
    "\n",
    "        return pd.Series(outputs)\n",
    "\n",
    "    return confusion_matrix_udf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c248630d-f9d7-4901-86e4-22cd0d0320ae",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "test_model = load_model(UCModelName(\"edav_dev_csels\", \"towerscout\", \"yolov10_models\"), \"small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "418b62d7-6940-4906-93bb-e0eef884112a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(test_model.model.names)\n",
    "print(len(test_model.model.names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a46306bf-43e9-4cce-a43e-5ef0c9e662e5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = spark.read.format(\"delta\").table(\"edav_dev_csels.towerscout.benchmark_scored\").selectExpr(\"content\", \"modificationTime\", \"results.bboxes as bboxes\").limit(100)\n",
    "\n",
    "# Note we must flatten because if we don't then casting the resulting 2D arrays will give us a numpy array of weird objects (numpy.object_) and not a true 2D numpy array\n",
    "# This should be fine since it just requires an extra reshape operation which is cheap\n",
    "df = df.selectExpr(\n",
    "    '*',\n",
    "    \"transform(bboxes, x -> x.class) AS class\",\n",
    "    \"flatten(transform(bboxes, x -> array(x.x1, x.y1, x.x2, x.y2))) AS bboxes_flattened\",\n",
    ")\n",
    "\n",
    "df = get_struct_counts(df, \"modificationTime\", \"bboxes\", filter_clause=\"x.class = 0 and x.class_name = 'ct'\", time_window_days = 100000000)\n",
    "aggregated_num_structs = df.agg({\"num_structs\": \"sum\"})\n",
    "\n",
    "print(f\"Total ground truth bounding boxes: {aggregated_num_structs.collect()[0][0]}\")\n",
    "\n",
    "display(df.limit(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f88ba262-ff3d-45cf-8bb7-872f07bddfd7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "uc_model_name = UCModelName(\"edav_dev_csels\", \"towerscout\", \"yolov10_models\")\n",
    "confusion_matrix_udf = make_confusion_matrix_udf(uc_model_name, uc_alias=\"small\", conf=0.5, iou_thres=0.2)\n",
    "\n",
    "df_with_conf = df.withColumn(\"conf_mat\", confusion_matrix_udf(F.col(\"content\"), F.col(\"bboxes_flattened\"), F.col(\"class\")))\n",
    "display(df_with_conf.limit(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cf86e326-4f18-480a-ba80-b4416b7a8a98",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "@F.pandas_udf(returnType=\"array<array<integer>>\")\n",
    "def sum_arrays(arrays: pd.Series) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Sums all the arrays in the input Series. All arrays must be of same shape.\n",
    "    The return type hint `np.ndarray` indicates that the function returns \n",
    "    a numpy array. This function is used to perform a grouped aggregation \n",
    "    on a column containing 2D arrays. \n",
    "    \"\"\"\n",
    "    return arrays.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "68b158e6-a5e2-4df8-8f76-121c4209c531",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# perform a global aggregation on the confusion matrices\n",
    "cm = df_with_conf.select(sum_arrays(F.col(\"conf_mat\")).alias(\"total_confusion_matrix\"))\n",
    "display(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cb4483bc-bd53-4f8f-8218-c47412af2a04",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "confusion_mat = np.array(cm.collect()[0][\"total_confusion_matrix\"])  # list of lists\n",
    "print(confusion_mat.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bbfe4d67-c82d-4aca-bb13-7584a65ff19b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, f1_score, recall_score, precision_score\n",
    "\n",
    "\n",
    "def reconstruct_labels_and_preds(\n",
    "    confusion_matrix: np.ndarray,\n",
    ") -> tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Given an confusion matrix of shape NxN, reconstruct the ground truth and predicted labels.\n",
    "    NOTE: we assume that the confusion matrix has 'predicted' counts on the y-axis/dimension\n",
    "    and 'true' counts on the x-axis/dimension.\n",
    "\n",
    "    Args:\n",
    "        confusion_matrix: The NxN confusion matrix.\n",
    "    Retruns:\n",
    "        A tuple of two 1D numpy arrays: ground truth labels and predicted labels.\n",
    "    \"\"\"\n",
    "\n",
    "    num_classes = confusion_matrix.shape[0]  # Number of classes\n",
    "    ground_truth = []\n",
    "    predicted = []\n",
    "\n",
    "    for actual_class in range(num_classes):\n",
    "        for predicted_class in range(num_classes):\n",
    "            count = confusion_matrix[actual_class, predicted_class]\n",
    "\n",
    "            # Append the actual class 'count' times\n",
    "            ground_truth.extend([actual_class] * count)\n",
    "\n",
    "            # Append the predicted class 'count' times\n",
    "            predicted.extend([predicted_class] * count)\n",
    "\n",
    "    return np.array(ground_truth), np.array(predicted)\n",
    "\n",
    "\n",
    "def compute_metrics(confusion_matrix: np.ndarray) -> dict[str, float]:\n",
    "    \"\"\"\n",
    "    Compute per-class recall, precision, F1 score, and their micro and macro averages.\n",
    "\n",
    "    Args:\n",
    "        confusion_matrix: The NxN confusion matrix. The\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing per-class metrics and averaged metrics.\n",
    "    \"\"\"\n",
    "\n",
    "    true_labels, preds = reconstruct_labels_and_preds(confusion_matrix)\n",
    "    \n",
    "    # ignore background label when computing overal metrics see:\n",
    "    # tp_fp() function of ConfusionMatrix class\n",
    "    labels = [i for i in range(0, confusion_matrix.shape[0]-1)]\n",
    "    metrics = {\n",
    "        \"micro_f1\": f1_score(true_labels, preds, average=\"micro\", labels=labels),\n",
    "        \"macro_f1\": f1_score(true_labels, preds, average=\"macro\", labels=labels),\n",
    "        \"per_class_f1\": f1_score(true_labels, preds, average=None),\n",
    "        \"micro_recall\": recall_score(true_labels, preds, average=\"micro\", labels=labels),\n",
    "        \"macro_recall\": recall_score(true_labels, preds, average=\"macro\", labels=labels),\n",
    "        \"per_class_recall\":  recall_score(true_labels, preds, average=None),\n",
    "        \"micro_precision\": precision_score(true_labels, preds, average=\"micro\", labels=labels),\n",
    "        \"macro_precision\": precision_score(true_labels, preds, average=\"macro\", labels=labels),\n",
    "        \"per_class_precision\": precision_score(true_labels, preds, average=None),\n",
    "    }\n",
    "\n",
    "    return metrics\n",
    "\n",
    "\n",
    "print(confusion_mat)\n",
    "true_labels, predicted_labels = reconstruct_labels_and_preds(confusion_mat)   \n",
    "\n",
    "# we may want to not include the background class metrics in the overall precision metric cuz it seems to be 0 all the time. Which makes sense\n",
    "print(confusion_matrix(true_labels, predicted_labels))\n",
    "\n",
    "print(compute_metrics(confusion_mat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3942d1b4-2e72-4ea6-b711-c413b080bc96",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "test_cm = np.array( [ [0, 8, 0], \n",
    "                      [0, 1,  3], \n",
    "                      [9,  6, 1]] )\n",
    "\n",
    "\n",
    "preds = np.array([0,0,0, 1,1,1,1, 2,2,2])\n",
    "true_labels = np.array([0,0,0, 1,1,1,1, 2,2,2])\n",
    "\n",
    "gt, pred = reconstruct_labels_and_preds(test_cm)\n",
    "print(test_cm, \"\\n\")\n",
    "print(confusion_matrix(gt, pred))\n",
    "\n",
    "# recall_score(gt, pred, labels=[1,2], average=None)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "benchmark_dataset",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
