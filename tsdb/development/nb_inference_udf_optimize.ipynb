{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f7b09f0e-76be-4f2f-930f-5b6cb8a6e328",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "from json import loads\n",
    "from typing import Any, TypedDict\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.transforms.functional import pil_to_tensor\n",
    "\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "import PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d0f175f2-a5b7-4e8d-80f3-66fbd97e9391",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "class ImageMetadata(TypedDict):\n",
    "    \"\"\"\n",
    "    A class to represent image metadata.\n",
    "    height: the image height\n",
    "    width: the image width\n",
    "    lat: the latitude of the image\n",
    "    long: the longitude of the image\n",
    "    image_id: the id of the image\n",
    "    map_provider: the map provider the image is from \n",
    "    image: The PIL image object\n",
    "    \"\"\"\n",
    "    height: int\n",
    "    width: int\n",
    "    lat: float\n",
    "    long: float\n",
    "    image_id: int\n",
    "    map_provider: str\n",
    "    image: PIL.Image\n",
    "\n",
    "\n",
    "def get_image_metadata(image_binary: bytes) -> ImageMetadata:  # pragma: no cover\n",
    "        # Try to read the image and if we fail, we have to default to\n",
    "        # to the null image case\n",
    "        image_binary = BytesIO(image_binary)\n",
    "\n",
    "        try:\n",
    "            image = PIL.Image.open(image_binary)\n",
    "            exif = image._getexif()\n",
    "\n",
    "        except FileNotFoundError:\n",
    "            exif = None\n",
    "        except UnicodeDecodeError:\n",
    "            exif = None\n",
    "\n",
    "        user_comment_exif_id = 37510\n",
    "\n",
    "        if exif is None or user_comment_exif_id not in exif:\n",
    "            # we need to return with default values\n",
    "            fake_image = PIL.Image.new(\"RGB\", (640, 640), \"black\")\n",
    "            return {\n",
    "                \"height\": 640,\n",
    "                \"width\": 640,\n",
    "                \"lat\": 0.0,\n",
    "                \"long\": 0.0,\n",
    "                \"image_id\": -1,\n",
    "                \"map_provider\": \"unknown\",\n",
    "                \"image\": fake_image\n",
    "            }\n",
    "        \n",
    "        try:\n",
    "            user_comment_exif = exif[user_comment_exif_id]\n",
    "            exif_dict = loads(\n",
    "                user_comment_exif.decode(\"utf-8\").replace(\"\\'\", \"\\\"\")\n",
    "            )\n",
    "        \n",
    "        except UnicodeDecodeError as e:\n",
    "            # can we gracefully handle this?\n",
    "            raise ValueError(f\"Unable to decode exif data: {e}\")\n",
    "        \n",
    "        image_id = -1 if \"id\" not in exif_dict else int(exif_dict[\"id\"])\n",
    "        return {\n",
    "            \"height\": image.height,\n",
    "            \"width\": image.width,\n",
    "            \"lat\": exif_dict[\"lat\"],\n",
    "            \"long\": exif_dict[\"lng\"],\n",
    "            \"image_id\": image_id,\n",
    "            \"map_provider\": exif_dict[\"mapProvider\"],\n",
    "            \"image\": image\n",
    "        }\n",
    "\n",
    "\n",
    "class ImageBinaryDataset(Dataset):\n",
    "    def __init__(self, images):\n",
    "        self.images = images\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, index) -> ImageMetadata:\n",
    "         return get_image_metadata(self.images[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "28ad7951-f8fa-4d27-b940-3ada36f72c1a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# request_id = \"be69e91f\"\n",
    "# user_id = \"cnu4\"\n",
    "# dbutils.fs.cp(f\"/Volumes/edav_dev_csels/towerscout/images/maps/bronze/{user_id}/{request_id}\", \"/Volumes/edav_dev_csels/towerscout/misc/unit_tests/image_binary_dataset/\", recurse=True)\n",
    "\n",
    "dbutils.fs.mv('/Volumes/edav_dev_csels/towerscout/misc/unit_tests/index.json', \"/Volumes/edav_dev_csels/towerscout/misc/unit_tests/mosaic_streaming_unit_test/\", recurse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f4e979a6-c02e-4040-b96c-065beffff209",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "request_id = \"be69e91f\"\n",
    "user_id = \"cnu4\"\n",
    "base_path = f\"/Volumes/edav_dev_csels/towerscout/images/maps/bronze/{user_id}/{request_id}\"\n",
    "\n",
    "\n",
    "image_df = (\n",
    "    spark\n",
    "    .read\n",
    "    .format(\"binaryFile\")\n",
    "    .load(base_path) # parameterize\n",
    "    .select(\"content\")\n",
    "    .limit(20)\n",
    "    #.repartition(8)\n",
    "    #.withColumn(\"inference\", yolo_inference_udf(F.col(\"content\")))\n",
    ")\n",
    "\n",
    "#display(image_df)\n",
    "\n",
    "image_df = image_df.toPandas()\n",
    "image_bins = image_df[\"content\"]\n",
    "\n",
    "print(image_df)\n",
    "bin_dataset = ImageBinaryDataset(image_bins)\n",
    "\n",
    "display(bin_dataset[18])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3d5f663c-ee4a-4529-b883-bf2620c43d05",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(type(bin_dataset))\n",
    "assert isinstance(bin_dataset, ImageBinaryDataset)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "nb_inference_udf_optimize",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
